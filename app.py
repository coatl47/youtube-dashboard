import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re
import io
from datetime import datetime

# 1. API ì„¤ì •
API_KEY = st.secrets["YOUTUBE_API_KEY"]
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]

youtube = build('youtube', 'v3', developerKey=API_KEY)
genai.configure(api_key=GEMINI_API_KEY)

# [í•´ê²° í¬ì¸íŠ¸] ëª¨ë¸ ì´ë¦„ì„ ë‹¨ìˆœí™”í•˜ì—¬ í˜¸ì¶œí•©ë‹ˆë‹¤. 
# ëŒ€ë¶€ë¶„ì˜ ìµœì‹  í™˜ê²½ì—ì„œëŠ” 'gemini-1.5-flash'ë§Œìœ¼ë¡œ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.
model = genai.GenerativeModel('gemini-1.5-flash')

# 2. ìˆ˜ì§‘ í•¨ìˆ˜
@st.cache_data(ttl=600)
def get_stats(v_id):
    try:
        r = youtube.videos().list(part="snippet,statistics", id=v_id).execute()
        return {
            "title": r['items'][0]['snippet']['title'],
            "v_count": int(r['items'][0]['statistics']['viewCount']),
            "l_count": int(r['items'][0]['statistics']['likeCount']),
            "c_count": int(r['items'][0]['statistics']['commentCount'])
        }
    except: return None

def get_comms(v_id, limit=30):
    comms = []
    try:
        r = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=50, order="time").execute()
        for item in r['items']:
            snip = item['snippet']['topLevelComment']['snippet']
            # HTML íƒœê·¸ ë° ì¤„ë°”ê¿ˆ ì œê±°í•˜ì—¬ AI ë¶„ì„ íš¨ìœ¨ ë†’ì„
            clean_txt = re.sub('<[^<]+?>', '', snip['textDisplay']).replace('\n', ' ')
            comms.append({"time": snip['publishedAt'], "text": clean_txt})
            if len(comms) >= limit: break
        return pd.DataFrame(comms)
    except: return pd.DataFrame()

# 3. AI ë¶„ì„ í•¨ìˆ˜ (íŒŒì‹± ê°•í™”)
def analyze_ai(df):
    if df.empty: return pd.DataFrame()
    raw_txt = "\n".join([f"- {t[:120]}" for t in df['text']])
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìœ íŠœë¸Œ ëŒ“ê¸€ë“¤ì„ ë¶„ì„í•˜ì„¸ìš”.
    
    [ì§€ì¹¨]
    1. ì£¼ì œ(ë¶„ë¥˜)ë¥¼ ì˜ìƒ ë‚´ìš©ì— ë§ê²Œ ì§ì ‘ ìƒì„±í•˜ì„¸ìš” (ìµœëŒ€ 9ê°œ).
    2. ëª¨ë“  ëŒ“ê¸€ì„ [ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ, ë‚´ìš©]ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    3. ë°˜ë“œì‹œ ì•„ë˜ì˜ CSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì€ ìƒëµí•˜ì„¸ìš”.
    4. êµ¬ë¶„ìëŠ” ë°˜ë“œì‹œ '|'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    
    í˜•ì‹:
    ê°ì„±|ë¶„ë¥˜|í‚¤ì›Œë“œ|ë‚´ìš©
    
    ëŒ“ê¸€ ëª©ë¡:
    {raw_txt}
    """
    try:
        # ëª¨ë¸ ì½˜í…ì¸  ìƒì„±
        response = model.generate_content(prompt)
        full_text = response.text.strip()
        
        # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ë¡œì§ (í…ìŠ¤íŠ¸ ë‚´ ë§ˆí¬ë‹¤ìš´ ì œê±° ë“±)
        clean_csv = re.sub(r'```csv\n|```', '', full_text)
        if "ê°ì„±|ë¶„ë¥˜" in clean_csv:
            start_idx = clean_csv.find("ê°ì„±|ë¶„ë¥˜")
            rdf = pd.read_csv(io.StringIO(clean_csv[start_idx:]), sep='|', on_bad_lines='skip', engine='python')
            rdf.columns = [c.strip() for c in rdf.columns]
            return rdf
        return pd.DataFrame()
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# 4. UI êµ¬ì„±
st.set_page_config(page_title="ìœ íŠœë¸Œ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“Š ìœ íŠœë¸Œ ì‹¤ì‹œê°„ ì—¬ë¡  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

url = st.text_input("ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="https://www.youtube.com/watch?v=...")

if url:
    m = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    if m:
        vid = m.group(1)
        
        with st.status("ë°ì´í„° ë¶„ì„ ì§„í–‰ ì¤‘...", expanded=True) as status:
            info = get_stats(vid)
            raw = get_comms(vid)
            final = analyze_ai(raw)
            if not final.empty:
                status.update(label="ë¶„ì„ ì„±ê³µ!", state="complete", expanded=False)
            else:
                status.update(label="ë¶„ì„ ì‹¤íŒ¨(ë°ì´í„° ì—†ìŒ)", state="error", expanded=False)

        if info and not final.empty:
            st.divider()
            st.subheader(f"ğŸ¥ ì˜ìƒ: {info['title']}")
            
            # ë©”íŠ¸ë¦­ ì§€í‘œ
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì¡°íšŒìˆ˜", f"{info['v_count']:,}")
            m2.metric("ì¢‹ì•„ìš”", f"{info['l_count']:,}")
            m3.metric("ëŒ“ê¸€ìˆ˜", f"{info['c_count']:,}")
            m4.metric("ìµœì¢… ì—…ë°ì´íŠ¸", datetime.now().strftime('%H:%M'))

            # ì‹œê°í™”
            c1, c2 = st.columns(2)
            with c1:
                st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ì¶”ì´")
                raw['time'] = pd.to_datetime(raw['time'])
                trend = raw.set_index('time').resample('H').size().reset_index(name='cnt')
                st.plotly_chart(px.line(trend, x='time', y='cnt', markers=True), use_container_width=True)
            with c2:
                st.subheader("ğŸ˜Š ì „ì²´ ê°ì„± ë¹„ìœ¨")
                s_counts = final['ê°ì„±'].value_counts().reset_index()
                st.plotly_chart(px.pie(s_counts, names='ê°ì„±', values='count', 
                                       color='ê°ì„±', color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë¶„ë¥˜ë³„ ë¶„ì„ ê·¸ë˜í”„
            st.subheader("ğŸ“ ì£¼ì œë³„ ì—¬ë¡  ë¶„ì„ (AI ìë™ ìƒì„±)")
            b_data = final.groupby(['ë¶„ë¥˜', 'ê°ì„±']).size().reset_index(name='v')
            st.plotly_chart(px.bar(b_data, x='v', y='ë¶„ë¥˜', color='ê°ì„±', orientation='h',
                                   color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ í…Œì´ë¸”")
            st.dataframe(final, use_container_width=True, height=400)
            st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", final.to_csv(index=False).encode('utf-8-sig'), f"analysis_{vid}.csv", "text/csv")

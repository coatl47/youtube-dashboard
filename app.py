import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re
import io
from datetime import datetime

# 1. API ë° ì„œë¹„ìŠ¤ ì„¤ì •
# Streamlit Secretsì— YOUTUBE_API_KEYì™€ GEMINI_API_KEYê°€ ì €ì¥ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
API_KEY = st.secrets["YOUTUBE_API_KEY"]
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]

youtube = build('youtube', 'v3', developerKey=API_KEY)
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# 2. ì˜ìƒ ì •ë³´ ë° ëŒ“ê¸€ ìˆ˜ì§‘ í•¨ìˆ˜
@st.cache_data(ttl=600)
def get_video_info(video_id):
    try:
        req = youtube.videos().list(part="snippet,statistics", id=video_id)
        res = req.execute()
        if not res['items']: return None
        item = res['items'][0]
        return {
            "title": item['snippet']['title'],
            "view": int(item['statistics']['viewCount']),
            "like": int(item['statistics']['likeCount']),
            "comm": int(item['statistics']['commentCount'])
        }
    except: return None

def get_comments(video_id, count=50):
    comments = []
    token = None
    try:
        while len(comments) < count:
            req = youtube.commentThreads().list(
                part="snippet", videoId=video_id, maxResults=100,
                pageToken=token, order="time"
            )
            res = req.execute()
            for item in res['items']:
                snippet = item['snippet']['topLevelComment']['snippet']
                comments.append({"time": snippet['publishedAt'], "comment": snippet['textDisplay']})
                if len(comments) >= count: break
            token = res.get('nextPageToken')
            if not token: break
        return pd.DataFrame(comments)
    except: return pd.DataFrame()

# 3. AI ë™ì  ë¶„ë¥˜ ë¶„ì„ í•¨ìˆ˜
def analyze_ai_dynamic(df):
    if df.empty: return pd.DataFrame()
    text_data = "\n".join([f"- {c}" for c in df['comment']])
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ“ê¸€ë“¤ì„ ë¶„ì„í•˜ì„¸ìš”.
    1. ì£¼ì œ(ë¶„ë¥˜)ë¥¼ ìŠ¤ìŠ¤ë¡œ ë„ì¶œí•˜ë˜ ìµœëŒ€ 9ê°œê¹Œì§€ë§Œ ìƒì„±í•˜ì„¸ìš”.
    2. ëª¨ë“  ëŒ“ê¸€ì„ [ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ]ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    3. ë°˜ë“œì‹œ ì•„ë˜ CSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. êµ¬ë¶„ìëŠ” '|'ì…ë‹ˆë‹¤.
    í˜•ì‹: ê°ì„±|ë¶„ë¥˜|í‚¤ì›Œë“œ|ëŒ“ê¸€ë‚´ìš©
    ê°ì„±: ê¸ì •, ì¤‘ë¦½, ë¶€ì • ì¤‘ ì„ íƒ
    
    ëŒ“ê¸€ ëª©ë¡:
    {text_data}
    """
    try:
        response = model.generate_content(prompt)
        clean_res = response.text.strip().replace('```csv', '').replace('```', '')
        result_df = pd.read_csv(io.StringIO(clean_res), sep='|', on_bad_lines='skip')
        result_df.columns = [c.strip() for c in result_df.columns]
        return result_df
    except: return pd.DataFrame()

# 4. ë ˆì´ì•„ì›ƒ ë° ì‹œê°í™”
st.set_page_config(page_title="ìœ íŠœë¸Œ ëª¨ë‹ˆí„°ë§", layout="wide")
st.title("ğŸ“Š ìœ íŠœë¸Œ ì‹¤ì‹œê°„ ì—¬ë¡  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

url = st.text_input("ìœ íŠœë¸Œ URL ì…ë ¥", placeholder="https://www.youtube.com/watch?v=...")

if url:
    match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    if match:
        v_id = match.group(1)
        with st.spinner('AI ë¶„ì„ ì¤‘...'):
            info = get_video_info(v_id)
            raw_df = get_comments(v_id)
            final_df = analyze_ai_dynamic(raw_df)

        if not final_df.empty:
            st.divider()
            st.subheader(f"ğŸ¥ {info['title']}")
            
            # ì§€í‘œ
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ì¡°íšŒìˆ˜", f"{info['view']:,}")
            c2.metric("ì¢‹ì•„ìš”", f"{info['like']:,}")
            c3.metric("ëŒ“ê¸€ìˆ˜", f"{info['comm']:,}")
            c4.metric("ë¶„ì„ì¼", datetime.now().strftime('%Y-%m-%d'))

            # ì°¨íŠ¸ ì˜ì—­
            col_a, col_b = st.columns(2)
            with col_a:
                st.subheader("ğŸ“ˆ ëŒ“ê¸€ ì‘ì„± ì¶”ì´")
                raw_df['time'] = pd.to_datetime(raw_df['time'])
                trend = raw_df.set_index('time').resample('H').size().reset_index(name='cnt')
                st.plotly_chart(px.line(trend, x='time', y='cnt'), use_container_width=True)
            with col_b:
                st.subheader("ğŸ˜Š ê°ì„± ë¶„í¬")
                sent = final_df['ê°ì„±'].value_counts().reset_index()
                st.plotly_chart(px.pie(sent, names='ê°ì„±', values='count', 
                                       color='ê°ì„±', color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„
            st.subheader("ğŸ“ ì£¼ì œë³„ ì—¬ë¡  ë¶„í¬ (AI ìë™ ìƒì„±)")
            bar_data = final_df.groupby(['ë¶„ë¥˜', 'ê°ì„±']).size().reset_index(name='v')
            order = final_df['ë¶„ë¥˜'].value_counts().index.tolist()
            st.plotly_chart(px.bar(bar_data, x='v', y='ë¶„ë¥˜', color='ê°ì„±', orientation='h',
                                   category_orders={"ë¶„ë¥˜": order},
                                   color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ë°ì´í„°")
            st.dataframe(final_df, use_container_width=True, height=400)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", final_df.to_csv(index=False).encode('utf-8-sig'), "result.csv", "text/csv")
    else:
        st.error("URL í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re
import io
from datetime import datetime

# 1. API ì„¤ì • (Secrets í™œìš©)
Y_KEY = st.secrets["YOUTUBE_API_KEY"]
G_KEY = st.secrets["GEMINI_API_KEY"]

youtube = build('youtube', 'v3', developerKey=Y_KEY)
genai.configure(api_key=G_KEY)

# 2. ì˜ìƒ ì •ë³´ ë° ëŒ“ê¸€ ìˆ˜ì§‘
@st.cache_data(ttl=600)
def get_video_info(v_id):
    try:
        r = youtube.videos().list(part="snippet,statistics", id=v_id).execute()
        item = r['items'][0]
        return {
            "title": item['snippet']['title'],
            "views": int(item['statistics']['viewCount']),
            "likes": int(item['statistics']['likeCount']),
            "comms": int(item['statistics']['commentCount'])
        }
    except: return None

def get_comments_data(v_id, limit=50):
    comments = []
    try:
        # ëŒ“ê¸€ 190ê°œê°€ ìˆë‹¤ë©´ maxResultsë¥¼ 100ìœ¼ë¡œ ì„¤ì •í•´ ë„‰ë„‰íˆ ê°€ì ¸ì˜µë‹ˆë‹¤.
        r = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=100, order="time").execute()
        for item in r['items']:
            txt = item['snippet']['topLevelComment']['snippet']['textDisplay']
            time = item['snippet']['topLevelComment']['snippet']['publishedAt']
            # íƒœê·¸ ì œê±° ë° ì •ì œ
            clean_txt = re.sub('<[^<]+?>', '', txt).replace('\n', ' ')
            comments.append({"time": time, "text": clean_txt})
            if len(comments) >= limit: break
        return pd.DataFrame(comments)
    except: return pd.DataFrame()

# 3. AI ë¶„ì„ í•¨ìˆ˜ (404 ì—ëŸ¬ ë°©ì§€ìš© í‘œì¤€ í˜¸ì¶œ)
def analyze_with_gemini(df):
    if df.empty: return pd.DataFrame()
    
    # [í•´ê²° í¬ì¸íŠ¸] ëª¨ë¸ ì„ ì–¸ ì‹œ ë¶ˆí•„ìš”í•œ ê²½ë¡œë¥¼ ì œê±°í•˜ê³  ì´ë¦„ë§Œ ì „ë‹¬í•©ë‹ˆë‹¤.
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ìµœì ì˜ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    raw_text = "\n".join([f"- {t[:150]}" for t in df['text']])
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ“ê¸€ë“¤ì„ ë¶„ì„í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    1. ì£¼ì œ(ë¶„ë¥˜)ë¥¼ ì˜ìƒ ë‚´ìš©ì— ë§ê²Œ ì§ì ‘ ìƒì„±í•´ (ìµœëŒ€ 9ê°œ).
    2. ëª¨ë“  ëŒ“ê¸€ì„ [ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ, ë‚´ìš©]ìœ¼ë¡œ ë¶„ë¥˜í•´.
    3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ '|' êµ¬ë¶„ìë¥¼ ì‚¬ìš©í•œ CSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´.
    4. í—¤ë” 'ê°ì„±|ë¶„ë¥˜|í‚¤ì›Œë“œ|ë‚´ìš©' ì™¸ì— ì–´ë–¤ ì„¤ëª…ë„ í•˜ì§€ ë§ˆ.
    
    ëŒ“ê¸€ ëª©ë¡:
    {raw_text}
    """
    
    try:
        # ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœì˜ í˜¸ì¶œ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        response = model.generate_content(prompt)
        res_txt = response.text.strip()
        
        # ì •ì œ ë° ë°ì´í„°í”„ë ˆì„í™”
        clean_csv = re.sub(r'```csv\n|```', '', res_txt)
        if "ê°ì„±|ë¶„ë¥˜" in clean_csv:
            start = clean_csv.find("ê°ì„±|ë¶„ë¥˜")
            final_df = pd.read_csv(io.StringIO(clean_csv[start:]), sep='|', on_bad_lines='skip', engine='python')
            final_df.columns = [c.strip() for c in final_df.columns]
            return final_df
        return pd.DataFrame()
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ë¥¼ ëª…í™•íˆ ë‚¨ê¹ë‹ˆë‹¤.
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# 4. ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ
st.set_page_config(page_title="ìœ íŠœë¸Œ ì—¬ë¡  ë¶„ì„", layout="wide")
st.title("ğŸ“Š ìœ íŠœë¸Œ ì‹¤ì‹œê°„ ì—¬ë¡  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

video_url = st.text_input("ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="https://www.youtube.com/watch?v=...")

if video_url:
    match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', video_url)
    if match:
        vid = match.group(1)
        
        with st.status("ìœ íŠœë¸Œ ë°ì´í„° ë° AI ë¶„ì„ ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
            info = get_video_info(vid)
            raw = get_comments_data(vid, limit=50) # ëŒ“ê¸€ ìˆ˜ì§‘ëŸ‰ ì¦ê°€
            final = analyze_with_gemini(raw)
            status.update(label="ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)

        if info and not final.empty:
            st.divider()
            st.subheader(f"ğŸ¥ ë¶„ì„ ì˜ìƒ: {info['title']}")
            
            # ì§€í‘œ ì˜ì—­
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì´ ì¡°íšŒìˆ˜", f"{info['views']:,}")
            m2.metric("ì¢‹ì•„ìš”", f"{info['likes']:,}")
            m3.metric("ëŒ“ê¸€ ìˆ˜", f"{info['comms']:,}")
            m4.metric("ë¶„ì„ì¼", datetime.now().strftime('%Y-%m-%d'))

            # ì°¨íŠ¸ ì˜ì—­
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ì¶”ì´")
                raw['time'] = pd.to_datetime(raw['time'])
                trend = raw.set_index('time').resample('H').size().reset_index(name='cnt')
                st.plotly_chart(px.line(trend, x='time', y='cnt', markers=True), use_container_width=True)
            with col2:
                st.subheader("ğŸ˜Š ê°ì„± ë¶„í¬")
                s_counts = final['ê°ì„±'].value_counts().reset_index()
                st.plotly_chart(px.pie(s_counts, names='ê°ì„±', values='count', 
                                       color='ê°ì„±', color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë¶„ë¥˜ë³„ ë¶„ì„
            st.subheader("ğŸ“ ì£¼ì œë³„ ì—¬ë¡  ë¶„í¬ (ìµœëŒ€ 9ê°œ)")
            b_data = final.groupby(['ë¶„ë¥˜', 'ê°ì„±']).size().reset_index(name='v')
            st.plotly_chart(px.bar(b_data, x='v', y='ë¶„ë¥˜', color='ê°ì„±', orientation='h',
                                   color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ì „ì²´ ë¶„ì„ ìƒì„¸ ë°ì´í„°")
            st.dataframe(final, use_container_width=True)
            st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", final.to_csv(index=False).encode('utf-8-sig'), "youtube_analysis.csv")
        elif info:
            st.warning("ë°ì´í„° ìˆ˜ì§‘ì€ ì„±ê³µí–ˆìœ¼ë‚˜, AI ë¶„ì„ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ì˜ ëª¨ë¸ ê¶Œí•œì„ í™•ì¸í•´ ë³´ì„¸ìš”.")
    else:
        st.error("ì˜¬ë°”ë¥¸ ìœ íŠœë¸Œ ì£¼ì†Œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")

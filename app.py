import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re
import io
from datetime import datetime

# 1. API ì„¤ì •
API_KEY = st.secrets["YOUTUBE_API_KEY"]
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]

youtube = build('youtube', 'v3', developerKey=API_KEY)
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# 2. ìˆ˜ì§‘ í•¨ìˆ˜
@st.cache_data(ttl=600)
def get_stats(v_id):
    try:
        r = youtube.videos().list(part="snippet,statistics", id=v_id).execute()
        return {
            "title": r['items'][0]['snippet']['title'],
            "v_count": int(r['items'][0]['statistics']['viewCount']),
            "l_count": int(r['items'][0]['statistics']['likeCount']),
            "c_count": int(r['items'][0]['statistics']['commentCount'])
        }
    except: return None

def get_comms(v_id, limit=30):
    comms = []
    try:
        r = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=50, order="time").execute()
        for item in r['items']:
            snip = item['snippet']['topLevelComment']['snippet']
            comms.append({"time": snip['publishedAt'], "text": snip['textDisplay']})
            if len(comms) >= limit: break
        return pd.DataFrame(comms)
    except: return pd.DataFrame()

# 3. AI ë¶„ì„ í•¨ìˆ˜ (íŒŒì‹± ë¡œì§ ëŒ€í­ ê°•í™”)
def analyze_ai(df):
    if df.empty: return pd.DataFrame()
    raw_txt = "\n".join([f"- {t[:100]}" for t in df['text']])
    
    prompt = f"""
    ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.
    
    [ì‘ì—… ì§€ì¹¨]
    1. ì£¼ì œ(ë¶„ë¥˜)ë¥¼ ì˜ìƒ ë‚´ìš©ì— ë§ê²Œ ì§ì ‘ ìƒì„±í•´ (ìµœëŒ€ 9ê°œ).
    2. ëª¨ë“  ëŒ“ê¸€ì„ [ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ, ë‚´ìš©]ìœ¼ë¡œ ë¶„ë¥˜í•´.
    3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ '|' êµ¬ë¶„ìë¥¼ ì‚¬ìš©í•œ CSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´.
    4. CSV í—¤ë”ëŠ” ë°˜ë“œì‹œ 'ê°ì„±|ë¶„ë¥˜|í‚¤ì›Œë“œ|ë‚´ìš©' ì´ì–´ì•¼ í•´.
    5. ì„œë¡ ì´ë‚˜ ê²°ë¡  ê°™ì€ ë¶€ê°€ ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.
    
    ëŒ“ê¸€ ëª©ë¡:
    {raw_txt}
    """
    try:
        response = model.generate_content(prompt)
        full_text = response.text.strip()
        
        # í…ìŠ¤íŠ¸ ì •ì œ: AIê°€ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì•ˆì— ë„£ì—ˆì„ ê²½ìš° ì¶”ì¶œ
        if "ê°ì„±|ë¶„ë¥˜" in full_text:
            # í—¤ë”ê°€ ì‹œì‘ë˜ëŠ” ì§€ì ë¶€í„° ëê¹Œì§€ ì¶”ì¶œ
            start_idx = full_text.find("ê°ì„±|ë¶„ë¥˜")
            clean_csv = full_text[start_idx:].strip()
            # ë§ˆí¬ë‹¤ìš´ ë‹«ëŠ” ê¸°í˜¸ ì œê±°
            clean_csv = clean_csv.replace("```", "")
            
            # ë°ì´í„°í”„ë ˆì„ ì½ê¸°
            rdf = pd.read_csv(io.StringIO(clean_csv), sep='|', on_bad_lines='skip', engine='python')
            rdf.columns = [c.strip() for c in rdf.columns]
            return rdf
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# 4. UI êµ¬ì„±
st.set_page_config(page_title="ìœ íŠœë¸Œ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“Š ìœ íŠœë¸Œ ì‹¤ì‹œê°„ ì—¬ë¡  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

url = st.text_input("ìœ íŠœë¸Œ URL ì…ë ¥", placeholder="[https://www.youtube.com/watch?v=](https://www.youtube.com/watch?v=)...")

if url:
    m = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    if m:
        vid = m.group(1)
        
        with st.status("ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
            info = get_stats(vid)
            raw = get_comms(vid)
            final = analyze_ai(raw)
            status.update(label="ë°ì´í„° ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

        if info and not final.empty:
            st.divider()
            st.subheader(f"ğŸ¥ ë¶„ì„ ì˜ìƒ: {info['title']}")
            
            # ì§€í‘œ í‘œì‹œ
            i1, i2, i3, i4 = st.columns(4)
            i1.metric("ì¡°íšŒìˆ˜", f"{info['v_count']:,}")
            i2.metric("ì¢‹ì•„ìš”", f"{info['l_count']:,}")
            i3.metric("ëŒ“ê¸€ìˆ˜", f"{info['c_count']:,}")
            i4.metric("ìµœì¢… ì—…ë°ì´íŠ¸", datetime.now().strftime('%H:%M'))

            # ì‹œê°í™” ì°¨íŠ¸
            c1, c2 = st.columns(2)
            with c1:
                st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ë¶„í¬")
                raw['time'] = pd.to_datetime(raw['time'])
                trend = raw.set_index('time').resample('H').size().reset_index(name='cnt')
                st.plotly_chart(px.line(trend, x='time', y='cnt', markers=True), use_container_width=True)
            with c2:
                st.subheader("ğŸ˜Š ê°ì„± ë¶„ì„ ê²°ê³¼")
                s_counts = final['ê°ì„±'].value_counts().reset_index()
                st.plotly_chart(px.pie(s_counts, names='ê°ì„±', values='count', 
                                       color='ê°ì„±', color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë¶„ë¥˜ë³„ ë¶„ì„ (ê°€ë¡œ ë§‰ëŒ€)
            st.subheader("ğŸ“ AI ìë™ ì¶”ì¶œ ì£¼ì œë³„ ì—¬ë¡ ")
            b_data = final.groupby(['ë¶„ë¥˜', 'ê°ì„±']).size().reset_index(name='v')
            st.plotly_chart(px.bar(b_data, x='v', y='ë¶„ë¥˜', color='ê°ì„±', orientation='h',
                                   color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ì „ì²´ ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ì „ì²´ ìƒì„¸ ë¶„ì„ í…Œì´ë¸”")
            st.dataframe(final, use_container_width=True, height=400)
            
            st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", final.to_csv(index=False).encode('utf-8-sig'), f"{vid}_analysis.csv", "text/csv")
        else:
            st.warning("âš ï¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìœ¼ë‚˜ AIê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. URLì´ ì˜¬ë°”ë¥¸ì§€, í˜¹ì€ ëŒ“ê¸€ì´ ì¶©ë¶„í•œì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")

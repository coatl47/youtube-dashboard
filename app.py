import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re
import time
from datetime import datetime


# 1. ì„¤ì • ë° API ì—°ê²°
API_KEY = st.secrets["YOUTUBE_API_KEY"]
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"] # Gemini API í‚¤ í•„ìš”

youtube = build('youtube', 'v3', developerKey=API_KEY)
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

# 2. ë¹„ë””ì˜¤ ì •ë³´ ë° ëŒ“ê¸€ ìˆ˜ì§‘ í•¨ìˆ˜
def get_video_stats(video_id):
    request = youtube.videos().list(part="snippet,statistics", id=video_id)
    response = request.execute()
    item = response['items'][0]
    return {
        "title": item['snippet']['title'],
        "view_count": int(item['statistics']['viewCount']),
        "like_count": int(item['statistics']['likeCount']),
        "comment_count": int(item['statistics']['commentCount'])
    }

def get_comments_with_time(video_id, max_count=100):
    comments = []
    next_page_token = None
    while len(comments) < max_count:
        request = youtube.commentThreads().list(
            part="snippet", videoId=video_id, maxResults=100,
            pageToken=next_page_token, order="time"
        )
        response = request.execute()
        for item in response['items']:
            snippet = item['snippet']['topLevelComment']['snippet']
            comments.append({
                "time": snippet['publishedAt'],
                "comment": snippet['textDisplay']
            })
            if len(comments) >= max_count: break
        next_page_token = response.get('nextPageToken')
        if not next_page_token: break
    return pd.DataFrame(comments)

# 3. AI ë¶„ì„ í•¨ìˆ˜ (ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ í•œ ë²ˆì— ì¶”ì¶œ)
def analyze_comments_ai(df):
    # ë¶„ì„ ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ 50ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜ ìƒ˜í”Œë§ ê¶Œì¥
    sample_text = "\n".join([f"- {c}" for c in df['comment'].head(30)])
    
    prompt = f"""
    ì•„ë˜ ìœ íŠœë¸Œ ëŒ“ê¸€ë“¤ì„ ë¶„ì„í•´ì„œ ê° ëŒ“ê¸€ë³„ë¡œ [ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ]ë¥¼ ì¶”ì¶œí•´ì¤˜.
    ë¶„ë¥˜ëŠ” ë‹¤ìŒ 9ê°œ ì¤‘ í•˜ë‚˜ë¡œë§Œ ì„ íƒí•´: ê¸°ì´ˆì—°ê¸ˆ, ë³´í—˜ë£Œì§€ì›, ì£¼íƒì‚¬ì—…, ê¸°ê¸ˆì„±ê³¼, ê¸°ê¸ˆë…ë¦½ì„±, ì¹˜ë§¤ì•ˆì‹¬ì§€ì›, ì½”ìŠ¤ë‹¥, ì •ì±…ë¬¸ì˜, ê¸°íƒ€.
    ê°ì„±ì€ 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •' ì¤‘ í•˜ë‚˜ì•¼.
    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ CSV í˜•ì‹ì„ ì§€ì¼œì¤˜. (í˜•ì‹: ê°ì„±|ë¶„ë¥˜|í‚¤ì›Œë“œ|ì›ë³¸ëŒ“ê¸€ë‚´ìš©)
    
    ëŒ“ê¸€:
    {sample_text}
    """
    
    try:
        response = model.generate_content(prompt)
        # ê²°ê³¼ íŒŒì‹± ë¡œì§ (ì˜ˆì‹œìš© ë‹¨ìˆœ êµ¬í˜„)
        # ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” response.textë¥¼ ì •ì œí•˜ì—¬ DataFrameìœ¼ë¡œ ê²°í•©í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
        st.success("AI ë¶„ì„ ì™„ë£Œ")
        return response.text
    except:
        return None

# 4. UI êµ¬ì„±
st.set_page_config(page_title="êµ­ë¯¼ì—°ê¸ˆ ìœ íŠœë¸Œ ëª¨ë‹ˆí„°ë§", layout="wide")
st.title("ğŸ“Š êµ­ë¯¼ì—°ê¸ˆ ìœ íŠœë¸Œ ì—¬ë¡  ëª¨ë‹ˆí„°ë§")

video_url = st.text_input("https://www.youtube.com/watch?v=fNHLffyXnQM")

if video_url:
    video_id = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', video_url).group(1)
    stats = get_video_stats(video_id)
    df = get_comments_with_time(video_id)

    # ìƒë‹¨ ì§€í‘œ (Metric)
    st.divider()
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("ì´ ì¡°íšŒìˆ˜", f"{stats['view_count']:,}")
    m2.metric("ì¢‹ì•„ìš”", f"{stats['like_count']:,}")
    m3.metric("ëŒ“ê¸€ ìˆ˜", f"{stats['comment_count']:,}")
    m4.metric("ìµœì¢… ì—…ë°ì´íŠ¸", datetime.now().strftime('%Y-%m-%d %H:%M'))

    # ë ˆì´ì•„ì›ƒ êµ¬ì„±
    col1, col2 = st.columns([1, 1])

    with col1:
        # 1. ì‹œê°„ëŒ€ë³„ ëˆ„ì  ì¶”ì´ (ì¡°íšŒìˆ˜ ëŒ€ì‹  ëŒ“ê¸€ ì‘ì„± ì¶”ì´ë¡œ ëŒ€ì²´ ì‹œê°í™”)
        st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ì‘ì„± ì¶”ì´")
        df['time'] = pd.to_datetime(df['time'])
        df_trend = df.set_index('time').resample('H').size().reset_index(name='counts')
        fig_line = px.line(df_trend, x='time', y='counts', title="ì‹œê°„ë³„ ìœ ì…ëŸ‰")
        st.plotly_chart(fig_line, use_container_width=True)

    with col2:
        # 2. ì „ì²´ ê°ì„± ë¶„í¬
        st.subheader("ğŸ˜Š ì „ì²´ ê°ì„± ë¶„í¬")
        # (ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìœ„í•œ ì„ì‹œ ë°ì´í„° - ì‹¤ì œ ë¶„ì„ê°’ ë°˜ì˜ í•„ìš”)
        sentiment_data = pd.DataFrame({'status': ['ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½'], 'value': [60, 25, 15]})
        fig_pie = px.pie(sentiment_data, names='status', values='value', 
                         color='status', color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'})
        st.plotly_chart(fig_pie, use_container_width=True)

    # 3. ë¶„ë¥˜ë³„ ì—¬ë¡  (ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„)
    st.subheader("ğŸ“ ì£¼ì œë³„ ì—¬ë¡  ë¶„í¬")
    category_data = pd.DataFrame({
        'ë¶„ë¥˜': ['ê¸°ì´ˆì—°ê¸ˆ', 'ë³´í—˜ë£Œì§€ì›', 'ì£¼íƒì‚¬ì—…', 'ê¸°ê¸ˆì„±ê³¼'],
        'ê¸ì •': [20, 15, 10, 30],
        'ë¶€ì •': [5, 10, 2, 20]
    }).melt(id_vars='ë¶„ë¥˜', var_name='ê°ì„±', value_name='ìˆ˜ì¹˜')
    
    fig_bar = px.bar(category_data, x='ìˆ˜ì¹˜', y='ë¶„ë¥˜', color='ê°ì„±', orientation='h',
                     color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B'})
    st.plotly_chart(fig_bar, use_container_width=True)

    # 4. ì „ì²´ ë¶„ì„ ë°ì´í„° í…Œì´ë¸”
    st.subheader("ğŸ“‹ ì „ì²´ ë¶„ì„ ë°ì´í„°")
    # ë¶„ì„ëœ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ (ì˜ˆì‹œ)
    analysis_df = pd.DataFrame({
        'ê°ì„±': ['ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½', 'ê¸ì •'],
        'ë¶„ë¥˜': ['ê¸°ì´ˆì—°ê¸ˆ', 'ë³´í—˜ë£Œì§€ì›', 'ê¸°ê¸ˆì„±ê³¼', 'ì£¼íƒì‚¬ì—…'],
        'í‚¤ì›Œë“œ': ['ìˆ˜ê¸‰ì•¡', 'ë¶€ë‹´', 'ìˆ˜ìµë¥ ', 'ì²­ì•½'],
        'ëŒ“ê¸€ ë‚´ìš©': df['comment'].head(4).values
    })
    
    st.dataframe(analysis_df, use_container_width=True, height=400)
    
    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    csv = analysis_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("CSV ë‹¤ìš´ë¡œë“œ", csv, "analysis_result.csv", "text/csv")


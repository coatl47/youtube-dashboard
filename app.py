import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re
import io
from datetime import datetime

# 1. API ì„¤ì •
API_KEY = st.secrets["YOUTUBE_API_KEY"]
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]

youtube = build('youtube', 'v3', developerKey=API_KEY)
genai.configure(api_key=GEMINI_API_KEY)

# [í•µì‹¬ ìˆ˜ì •] ë“œë¡­ë‹¤ìš´ ê¸°ë³¸ê°’ì¸ 'gemini-3-pro'ë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
# ë§Œì•½ 3 Proì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´ 'gemini-3-flash'ë¡œ ì‹œë„í•˜ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.
try:
    model = genai.GenerativeModel('gemini-3-pro')
except:
    model = genai.GenerativeModel('gemini-3-flash')

# 2. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
@st.cache_data(ttl=600)
def get_stats(v_id):
    try:
        r = youtube.videos().list(part="snippet,statistics", id=v_id).execute()
        item = r['items'][0]
        return {
            "title": item['snippet']['title'],
            "v_count": int(item['statistics']['viewCount']),
            "l_count": int(item['statistics'].get('likeCount', 0)),
            "c_count": int(item['statistics'].get('commentCount', 0))
        }
    except: return None

def get_comms(v_id, limit=50):
    comms = []
    try:
        r = youtube.commentThreads().list(part="snippet", videoId=v_id, maxResults=100, order="time").execute()
        for item in r.get('items', []):
            snip = item['snippet']['topLevelComment']['snippet']
            clean_txt = re.sub('<[^<]+?>', '', snip['textDisplay']).replace('\n', ' ')
            comms.append({"time": snip['publishedAt'], "text": clean_txt})
            if len(comms) >= limit: break
        return pd.DataFrame(comms)
    except: return pd.DataFrame()

# 3. AI ë¶„ì„ í•¨ìˆ˜
def analyze_ai(df):
    if df.empty: return pd.DataFrame()
    raw_txt = "\n".join([f"- {t[:150]}" for t in df['text']])
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìœ íŠœë¸Œ ëŒ“ê¸€ë“¤ì„ ë¶„ì„í•˜ì„¸ìš”.
    1. í•µì‹¬ ì£¼ì œ(ë¶„ë¥˜)ë¥¼ ì˜ìƒ ë‚´ìš©ì— ë§ê²Œ ìƒì„±í•˜ì„¸ìš” (ìµœëŒ€ 9ê°œ).
    2. ëª¨ë“  ëŒ“ê¸€ì„ [ê°ì„±, ë¶„ë¥˜, í‚¤ì›Œë“œ, ë‚´ìš©]ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
    3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ '|' êµ¬ë¶„ìë¥¼ ì‚¬ìš©í•œ CSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    4. ë°˜ë“œì‹œ í—¤ë” 'ê°ì„±|ë¶„ë¥˜|í‚¤ì›Œë“œ|ë‚´ìš©'ì„ í¬í•¨í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
    
    ëŒ“ê¸€ ëª©ë¡:
    {raw_txt}
    """
    try:
        response = model.generate_content(prompt)
        res_txt = response.text.strip()
        
        # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ (í—¤ë” ê¸°ì¤€ ì •ì œ)
        if "ê°ì„±|ë¶„ë¥˜" in res_txt:
            start_idx = res_txt.find("ê°ì„±|ë¶„ë¥˜")
            clean_csv = res_txt[start_idx:].replace('```csv', '').replace('```', '').strip()
            rdf = pd.read_csv(io.StringIO(clean_csv), sep='|', on_bad_lines='skip', engine='python')
            rdf.columns = [c.strip() for c in rdf.columns]
            return rdf
        return pd.DataFrame()
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# 4. UI êµ¬ì„±
st.set_page_config(page_title="ìœ íŠœë¸Œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“Š ìœ íŠœë¸Œ ì‹¤ì‹œê°„ ì—¬ë¡  ë¶„ì„ (Gemini 3 Pro)")

url = st.text_input("ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”")

if url:
    m = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    if m:
        vid = m.group(1)
        with st.status("ìµœì‹  Gemini 3 ëª¨ë¸ë¡œ ë¶„ì„ ì¤‘...", expanded=True) as status:
            info = get_stats(vid)
            raw = get_comms(vid)
            final = analyze_ai(raw)
            if not final.empty:
                status.update(label="ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
            else:
                status.update(label="ë¶„ì„ ì‹¤íŒ¨", state="error", expanded=False)

        if info and not final.empty:
            st.divider()
            st.subheader(f"ğŸ¥ ì˜ìƒ ì œëª©: {info['title']}")
            
            # ìƒë‹¨ ì§€í‘œ
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("ì´ ì¡°íšŒìˆ˜", f"{info['v_count']:,}")
            m2.metric("ì¢‹ì•„ìš”", f"{info['l_count']:,}")
            m3.metric("ëŒ“ê¸€ ìˆ˜", f"{info['c_count']:,}")
            m4.metric("ìµœì¢… ì—…ë°ì´íŠ¸", datetime.now().strftime('%H:%M'))

            # ì°¨íŠ¸ ì‹œê°í™”
            c1, c2 = st.columns(2)
            with c1:
                st.subheader("ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ì¶”ì´")
                raw['time'] = pd.to_datetime(raw['time'])
                trend = raw.set_index('time').resample('H').size().reset_index(name='cnt')
                st.plotly_chart(px.line(trend, x='time', y='cnt', markers=True), use_container_width=True)
            with c2:
                st.subheader("ğŸ˜Š ê°ì„± ë¶„ì„ ë¹„ìœ¨")
                s_counts = final['ê°ì„±'].value_counts().reset_index()
                st.plotly_chart(px.pie(s_counts, names='ê°ì„±', values='count', 
                                       color='ê°ì„±', color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë¶„ë¥˜ë³„ ë§‰ëŒ€ ê·¸ë˜í”„
            st.subheader("ğŸ“ ì£¼ì œë³„ ì—¬ë¡  ë¶„ì„ (ìµœëŒ€ 9ê°œ)")
            b_data = final.groupby(['ë¶„ë¥˜', 'ê°ì„±']).size().reset_index(name='v')
            st.plotly_chart(px.bar(b_data, x='v', y='ë¶„ë¥˜', color='ê°ì„±', orientation='h',
                                   color_discrete_map={'ê¸ì •':'#00CC96','ë¶€ì •':'#EF553B','ì¤‘ë¦½':'#AB63FA'}), use_container_width=True)

            # ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ì „ì²´ ìƒì„¸ ë°ì´í„°")
            st.dataframe(final, use_container_width=True)
            st.download_button("ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", final.to_csv(index=False).encode('utf-8-sig'), f"analysis_{vid}.csv")
